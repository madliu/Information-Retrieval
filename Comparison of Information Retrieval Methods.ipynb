{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluating different Information Retrieval Ranking Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment [Pyndri](https://github.com/cvangysel/pyndri) [[1](https://arxiv.org/abs/1701.00749)] was used which is  a python interface for [Indri](https://www.lemurproject.org/indri.php). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyndri\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from math import log\n",
    "import numpy as np\n",
    "import sys\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = pyndri.Index('index/')\n",
    "token2id, id2token, id2df = index.get_dictionary()\n",
    "# Collection frequency\n",
    "id2cf = index.get_term_frequencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading in the query file\n",
    "with open('/home/student/assignment/ap_88_89/topics_titles_validation.csv', 'r') as file:\n",
    "    querylist = file.readlines()\n",
    "queries = [(i.split(';')[0], i.split(',')[1].strip('\\n')) for i in querylist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining functions\n",
    "\n",
    "# Function to convert the query to a list of word_ids\n",
    "def query_preprocess(query):\n",
    "    query = re.sub('[!@#/$1234567890;()\"]',' ',query)\n",
    "    query_tokens = query.lower().split()\n",
    "    query_id_tokens = [token2id.get(query_token,0) for query_token in query_tokens]\n",
    "    query_id_tokens = [word_id for word_id in query_id_tokens if word_id > 0]\n",
    "    return query_id_tokens \n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate the tf \n",
    "def tf(document_id,query_term):\n",
    "    a = index.document(document_id)[1]\n",
    "    tf = a.count(query_term)\n",
    "    return tf\n",
    "\n",
    "\n",
    "# Function to calculate the idf of a query term\n",
    "def idf(query_term):\n",
    "    N = (index.maximum_document() - index.document_base())\n",
    "    df = id2df[query_term]\n",
    "    b = (N/int(df))\n",
    "    return log(b)\n",
    "\n",
    "\n",
    "\n",
    "# Function that combines the query term scores into a score for the whole query\n",
    "def query_dict(query_term_dict):\n",
    "    query_dict = {}\n",
    "\n",
    "    for query in queries:\n",
    "        query_term_ids = (query_preprocess(query[1]))\n",
    "        query_nr = (query[0].split(',')[0])\n",
    "        dict1 = {0:0}\n",
    "        query = Counter(dict1)\n",
    "        for query_term in query_term_ids:\n",
    "            query = query + Counter(query_term_dict[query_term])\n",
    "        query = query.most_common(1000)\n",
    "        query_dict[query_nr]= query\n",
    "\n",
    "    return query_dict\n",
    "\n",
    "# Function that handles negative scores (not implemented)\n",
    "def query_dictlogs(query_term_dict):\n",
    "    query_dict = {}\n",
    "\n",
    "    for query in queries:\n",
    "        query_term_ids = (query_preprocess(query[1]))\n",
    "        query_nr = (query[0].split(',')[0])\n",
    "        dict1 = {0:0}\n",
    "        query = Counter(dict1)\n",
    "        for query_term in query_term_ids:\n",
    "            query = query + Counter(query_term_dict)\n",
    "        query = query.most_common()[:-1000-1:-1]\n",
    "        query_dict[query_nr]= query\n",
    "\n",
    "    return query_dict\n",
    "\n",
    "# Function to create a data frame from the query dictionary.  \n",
    "def report(query2method, method = str()):\n",
    "    q_nums = []\n",
    "    doc_nums = []\n",
    "    score_x = []\n",
    "\n",
    "    for key, value in query2method.items():\n",
    "        for x in value:\n",
    "            q_nums.append(key)\n",
    "            doc_nums.append(x[0])\n",
    "            score_x.append(x[1])\n",
    "            \n",
    "    results = pd.DataFrame()\n",
    "    results['querynr'] = q_nums\n",
    "    results['doc numbers'] = doc_nums\n",
    "    results['scores'] = score_x\n",
    "\n",
    "    # Creating the column with document names\n",
    "    docnames = []\n",
    "    for doc in doc_nums:\n",
    "        docname = index.document(doc)[0]\n",
    "        docnames.append(docname)\n",
    "\n",
    "    # Adding missing columns\n",
    "    results['docnames']=docnames\n",
    "    results['method'] = method\n",
    "    results['dont know2'] = 'Q0'\n",
    "    results['rank']=results.groupby('querynr')['scores'].rank(ascending = False)\n",
    "    results = results[['querynr', 'dont know2', 'docnames', 'rank', 'scores', 'method']]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Making a list of all unique query terms \n",
    "\n",
    "all_word_ids = []\n",
    "for q in queries:\n",
    "    word_ids =  query_preprocess((q[1]))\n",
    "    for word_id in word_ids:\n",
    "        all_word_ids.append(word_id)\n",
    "\n",
    "all_word_ids = list(set(all_word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Making a dictionary with term frequencies {query_term_id:{document_id:tf}}\n",
    "query_term2tf = {}\n",
    "for query_term_id in all_word_ids:\n",
    "    query_term2tf[query_term_id] = {}\n",
    "for i, document_id in enumerate(range(index.document_base(),index.maximum_document())):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    a = index.document(document_id)[1]\n",
    "   \n",
    "    cnt = Counter(a)\n",
    "   \n",
    "    for word_id in all_word_ids:\n",
    "        if word_id not in cnt:\n",
    "            continue\n",
    "        tf = cnt[word_id]\n",
    "        query_term2tf[word_id][document_id] = tf\n",
    "    \n",
    "    #return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculating idf for each query term\n",
    "query_term_idf_scores = []\n",
    "for query_term in all_word_ids:\n",
    "    query_term_idf_scores.append(idf(query_term))\n",
    "    \n",
    "# Creating a dictionary {query_term:idf_score}\n",
    "query_term2idf=dict(zip(all_word_ids,query_term_idf_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Making a dictionary {query_term:{doc_nr:tf_idf score}}\n",
    "\n",
    "query_term2tfidf=copy.deepcopy(query_term2tf)\n",
    "for query_term in query_term2tfidf:\n",
    "    for key in query_term2tfidf[query_term]:\n",
    "        # this version was used in the first test\n",
    "        #query_term2tfidf[query_term][key]=query_term2tf[query_term][key]*query_term2idf[query_term]\n",
    "        \n",
    "        query_term2tfidf[query_term][key] = np.log2(1 + query_term2tf[query_term][key])\n",
    "        query_term2tfidf[query_term][key] = query_term2tfidf[query_term][key] * (np.log2(index.document_count()/id2df.get(query_term)))\n",
    "        \n",
    "        \n",
    "#print (query_term2tfidf[13][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary {query_number:{document,tf_idf}}\n",
    "query2tfidf = query_dict(query_term2tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Making a report \n",
    "tfidfresults = report(query2tfidf,\"tfidf\")\n",
    "print (tfidfresults.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating a csv report for trec_eval\n",
    "tfidf = tfidfresults.to_csv(\"tfidf2\", sep = '\\t', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculating the average length of a document\n",
    "sum = 0\n",
    "for i in range(index.document_base(),index.maximum_document()):\n",
    "    sum = sum + index.document_length(key)\n",
    "\n",
    "N = (index.maximum_document() - index.document_base())\n",
    "lenave = float(sum)/float(N)\n",
    "print (lenave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Making a dictionary {query_term:{doc_nr: bm25 score}}\n",
    "query_term2bm25=copy.deepcopy(query_term2tf)\n",
    "\n",
    "k1 = 1.5\n",
    "b = 0.75\n",
    "\n",
    "for query_term in query_term2bm25:\n",
    "    for key in query_term2bm25[query_term]:\n",
    "        query_term2bm25[query_term][key] = query_term2tf[query_term][key] * (k1+1)\n",
    "        query_term2bm25[query_term][key] = query_term2bm25[query_term][key]/(query_term2tf[query_term][key] + k1 * ((1 - b) + b * index.document_length(key))/lenave)\n",
    "        query_term2bm25[query_term][key] = query_term2bm25[query_term][key] * idf(query_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary {query_number:{document,tf_idf}}\n",
    "query2bm25 = query_dict(query_term2bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating a report\n",
    "bm25results = report(query2bm25,\"bm25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a csv report for trec_eval\n",
    "bm25 = bm25results.to_csv(\"bm25ver2\", sep = '\\t', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Tf-idf with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 30\n",
    "TF_MAP = (0.3132, 0.5399, 0.0192, 0.0037, 0.7578, \n",
    "          0.0834, 0.0274, 0.1631, 0.0012, 0.0895, \n",
    "          0.0021, 0.0018, 0.2607, 0.2303, 0.2875, \n",
    "          0.0048, 0.0190, 0.2998, 0.0001, 0.0326, \n",
    "          0.1025, 0.0010, 0.0013, 0.0583, 0.0404, \n",
    "          1.0000, 0.5681, 0.2795, 0.0192, 0.4809)\n",
    "\n",
    "\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "\n",
    "width = 0.5       # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, TF_MAP, width, color=\"#2b8cbe\")\n",
    "\n",
    "BM25 = (0.2634, 0.5121, 0.1233, 0.0011, 0.8352,\n",
    "        0.3336, 0.0483, 0.4170, 0.0119, 0.3899,\n",
    "        0.0015, 0.0006, 0.1729, 0.6019, 0.2168,\n",
    "        0.0513, 0.0670, 0.1963, 0.0000, 0.0169,\n",
    "        0.2772, 0.0004, 0.0057, 0.2050, 0.1533,\n",
    "        0.5889, 0.6141, 0.208, 0.2048, 0.3746)\n",
    "rects2 = ax.bar(ind + width, BM25, width, color=\"#e34a33\")\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Tf-idf score')\n",
    "ax.set_xticks(ind + width)\n",
    "ax.set_xticklabels((\"53\", \"57\", \"69\", \"74\", \"78\",\n",
    "                    \"86\", \"89\", \"90\", \"92\", \"93\",\n",
    "                    \"94\", \"95\", \"103\", \"111\", \"114\", \n",
    "                    \"120\", \"123\", \"135\", \"143\", \"144\", \n",
    "                    \"151\", \"155\", \"158\", \"165\", \"167\", \n",
    "                    \"170\", \"173\", \"180\", \"182\", \"192\"))\n",
    "\n",
    "\n",
    "ax.legend((rects1[0], rects2[0]), ('Tfidf', 'BM25'))\n",
    "\n",
    "#ax.invert_xaxis()\n",
    "\n",
    "fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "\n",
    "font = {'family' : 'monospace',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jelinek-Mercer Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Jelinek-Mercer language model\n",
    "lamda = 0.5 # Was varied 0.05, 0.1, 0.2, 0.5, 0.9\n",
    "\n",
    "# Making a dictionary {query_term:{doc_nr:jelinek score}}\n",
    "query_term2jelinek=copy.deepcopy(query_term2tf)\n",
    "\n",
    "for query_term in query_term2jelinek:\n",
    "    for doc_nr in query_term2jelinek[query_term]:\n",
    "        query_term2jelinek[query_term][doc_nr] = lamda * query_term2tf[query_term][doc_nr]/ index.document_length(doc_nr)\n",
    "        query_term2jelinek[query_term][doc_nr] = query_term2jelinek[query_term][doc_nr] + (1-lamda)*(id2cf[query_term]/index.total_terms())\n",
    "        #query_term2jelinek[query_term][doc_nr] = np.abs(np.log(query_term2jelinek[query_term][doc_nr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary {query_number:{document,tf_idf}}\n",
    "query2jelinek = query_dict(query_term2jelinek)\n",
    "query_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jelinekresults = report(query2jelinek, \"jelinek\")\n",
    "print (jelinekresults.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a csv report for trec_eval\n",
    "jelinek = jelinekresults.to_csv(\"jelinek05\", sep = '\\t', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet Prior Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dirichlet Prior language model \n",
    "mu = 0 \n",
    "\n",
    "# Making a dictionary {query_term:{doc_nr:dirichlet score}}\n",
    "query_term2dirichlet=copy.deepcopy(query_term2tf)\n",
    "\n",
    "for query_term in query_term2dirichlet:\n",
    "    for key in query_term2dirichlet[query_term]:\n",
    "        query_term2dirichlet[query_term][key] = index.document_length(key) / (index.document_length(key)+mu)\n",
    "        query_term2dirichlet[query_term][key] = query_term2dirichlet[query_term][key] * query_term2tf[query_term][key] / index.document_length(key)\n",
    "        query_term2dirichlet[query_term][key] = query_term2dirichlet[query_term][key] + (mu/(mu+index.document_length(key))) * id2cf[query_term]/index.total_terms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary {query_number:{document:jelinek}}\n",
    "query2dirichlet = query_dict(query_term2dirichlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a report\n",
    "dirichletresults = report(query2dirichlet,\"dirichlet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating a csv report for trec_eval\n",
    "dirichlet = dirichletresults.to_csv(\"dirichlet1500\", sep = '\\t', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Absolute Discounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Absolute discounting\n",
    "beta = 0.2\n",
    "\n",
    "# Making a dictionary {query_term:{doc_nr:absdisc score}}\n",
    "query_term2absdisc=copy.deepcopy(query_term2tf)\n",
    "\n",
    "for query_term in query_term2dirichlet:\n",
    "    for key in query_term2dirichlet[query_term]:\n",
    "        query_term2absdisc[query_term][key] = max(query_term2tf[query_term][key] - beta,0)/index.document_length(key)\n",
    "        query_term2absdisc[query_term][key] = query_term2absdisc[query_term][key] + beta * len(set(index.document(key)[1]))/index.document_length(key)\n",
    "        query_term2absdisc[query_term][key] = query_term2absdisc[query_term][key]* id2cf[query_term]/index.total_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a dictionary {query_number:{document:jelinek}}\n",
    "query2absdisc = query_dict(query_term2absdisc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a report\n",
    "absdiscresults = report(query2absdisc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a csv report for trec_eval\n",
    "\n",
    "absdisc = absdiscresults.to_csv(\"absdisc05\", sep = '\\t', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Language model plots showing NDCG@10 with varying values of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Jelinek\n",
    "NDCG_scores = [0.1903, 0.1903, 0.1925, 0.1903, 0.1944]\n",
    "lamda = [0.9, 0.5, 0.1, 0.2, 0.05]\n",
    "\n",
    "ax.set_ylabel('NDCG@10')\n",
    "ax.set_title('Jelinek: NDCG@10 for different lambda values')\n",
    "plt.scatter(lamda, NDCG_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dirichlet\n",
    "NDCG_scores = [0.2487, 0.2448, 0.2638, 0.2471]\n",
    "Mu_values = [1000, 2000, 500, 1500]\n",
    "\n",
    "ax.set_ylabel('NDCG@10')\n",
    "ax.set_title('Dirichlet: NDCG@10 for different mu-values')\n",
    "plt.scatter(Mu_values, NDCG_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Absolute discounting\n",
    "\n",
    "NDCG_scores = [0.0656, 0.0609, 0.06680]\n",
    "Beta_values = [0.5, 0.9, 0.1]\n",
    "\n",
    "ax.set_ylabel('NDCG@10')\n",
    "ax.set_title('Absolute discounting: NDCG@10 for different mu-values')\n",
    "plt.scatter(Beta_values, NDCG_scores)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
